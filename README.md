# Using BERT models for Sentiment Analysis
 
This project involves fine-tuning various BERT models and comparing their performance on an emotion classification task. The project uses the dair-ai/emotion dataset and evaluates the performance of different-sized BERT models: `bert-base-uncased`, `bert-base-cased`, `bert-large-uncased`, and `bert-large-cased`. I goes over sentiment analysis using the BERT models and cover essential text preprocessing techniques on text sources from X (formerly Twitter). Furthermore, I cover how to fine tune a BERT model on your data, and the performance evaluation of this model as well. The tutorial will also try to identify which BERT model gives the best performance for this particular task (detecting emotions from text). This notebook aims to provide a pipeline to analyze and understand sentiment and emotions from text, which could offer valuable insights for researchers in social sciences, marketing, and computational linguistics.

The project contains a python file, an ipynb notebook, which will help understand each step of the process better, and an html file which makes the tutorial easier to view in a web browser. 

##
Feel free to fork and take the project further if you would like. 

#### This tutorial is an extension of [a transformers tutorial](https://github.com/bentrevett/pytorch-sentiment-analysis) by Ben Trevett, in which a BERT model is used to detect the sentiment of comments from an IMDB dataset. Check out his tutorial as well!
